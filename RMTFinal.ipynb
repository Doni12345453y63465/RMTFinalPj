{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw7vVCXgsrRc",
        "outputId": "f2abba22-64af-4d11-cd48-10064dbb0984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preprocessing data...\n",
            "Splitting data...\n",
            "Evaluating models...\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Training Gradient Boosting...\n",
            "\n",
            "Training LightGBM-AFT...\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "Model Evaluation:\n",
            "                         MAE      RMSE      MAPE  R² (Accuracy)\n",
            "Random Forest      0.007292  0.040060  0.000143       0.999985\n",
            "Gradient Boosting  0.014442  0.025128  0.000266       0.999994\n",
            "LightGBM-AFT       1.329266  2.017358  0.024303       0.960921\n",
            "Neural Network     1.151935  3.003186  0.019878       0.913394\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from scipy.stats import zscore\n",
        "import lightgbm as lgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/1000 Buses Trajectory Dataset (1).csv\")\n",
        "\n",
        "    \n",
        "    data['Start'] = pd.to_datetime(data['Start'], format='%H:%M:%S', errors='coerce')\n",
        "    data['Hour'] = data['Start'].dt.hour\n",
        "    data['Weekday'] = data['Start'].dt.weekday\n",
        "    data['Month'] = data['Start'].dt.month\n",
        "    data['Day_of_Year'] = data['Start'].dt.dayofyear\n",
        "    data['Is_Weekend'] = data['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "\n",
        "    def convert_to_minutes(time_str):\n",
        "        try:\n",
        "            h, m, s = map(int, time_str.split(':'))\n",
        "            return h * 60 + m + s / 60\n",
        "        except:\n",
        "            return np.nan\n",
        "\n",
        "    data['Duration'] = data['Duration'].astype(str).apply(convert_to_minutes)\n",
        "    data = data.dropna(subset=['Start', 'Duration'])\n",
        "\n",
        "    \n",
        "    stop_features = [col for col in data.columns if \"Stop\" in col and \"to\" in col]\n",
        "    data['Route_Avg_Duration'] = data.groupby('Route')['Duration'].transform('mean')\n",
        "    data['Delay_Factor'] = data['Duration'] - data['Route_Avg_Duration']\n",
        "\n",
        "    \n",
        "    Q1 = data['Duration'].quantile(0.25)\n",
        "    Q3 = data['Duration'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    data.loc[(data['Duration'] < lower_bound) | (data['Duration'] > upper_bound), 'Duration'] = data['Duration'].median()\n",
        "\n",
        "    \n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    encoded_cats = pd.DataFrame(encoder.fit_transform(data[['Route', 'Service', 'Vehicle']]))\n",
        "    encoded_cats.columns = encoder.get_feature_names_out(['Route', 'Service', 'Vehicle'])\n",
        "    data = data.drop(columns=['Route', 'Service', 'Vehicle']).reset_index(drop=True)\n",
        "    data = pd.concat([data, encoded_cats], axis=1)\n",
        "\n",
        "    return data, stop_features, encoded_cats.columns\n",
        "\n",
        "class LightGBMAFT:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.params = {\n",
        "            'objective': 'regression',\n",
        "            'metric': 'mae',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'num_leaves': 31,\n",
        "            'learning_rate': 0.01,\n",
        "            'feature_fraction': 0.9,\n",
        "            'bagging_fraction': 0.8,\n",
        "            'bagging_freq': 5,\n",
        "            'verbose': -1,\n",
        "            'max_depth': 8,\n",
        "            'min_data_in_leaf': 20,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 0.1\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "        \n",
        "        mean_duration = np.mean(y)\n",
        "        X_scaled['mean_duration'] = mean_duration\n",
        "        X_scaled['time_ratio'] = y / mean_duration\n",
        "\n",
        "        \n",
        "        train_data = lgb.Dataset(X_scaled, label=y)\n",
        "        self.model = lgb.train(self.params, train_data, num_boost_round=200)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "        X_scaled['mean_duration'] = X_scaled.mean().mean()  \n",
        "        X_scaled['time_ratio'] = 1.0 \n",
        "\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "class CustomNNRegressor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = MLPRegressor(\n",
        "            hidden_layer_sizes=(200, 100, 50),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            alpha=0.001,\n",
        "            batch_size=32,\n",
        "            learning_rate='adaptive',\n",
        "            learning_rate_init=0.001,\n",
        "            max_iter=1000,\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.1,\n",
        "            n_iter_no_change=20,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        self.model.fit(X_scaled, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        results[name] = {\n",
        "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
        "            \"RMSE\": mean_squared_error(y_test, y_pred) ** 0.5,\n",
        "            \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
        "            \"R² (Accuracy)\": r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(results).T\n",
        "\n",
        "def main(file_path):\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    data, stop_features, encoded_cat_columns = load_and_preprocess_data(file_path)\n",
        "\n",
        "    features = ['Hour', 'Weekday', 'Month', 'Day_of_Year', 'Is_Weekend',\n",
        "                'Route_Avg_Duration', 'Delay_Factor'] + stop_features + list(encoded_cat_columns)\n",
        "    target = 'Duration'\n",
        "\n",
        "    print(\"Splitting data...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data[features], data[target], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    models = {\n",
        "        \"Random Forest\": RandomForestRegressor(\n",
        "            n_estimators=200,\n",
        "            max_depth=15,\n",
        "            min_samples_split=5,\n",
        "            random_state=42\n",
        "        ),\n",
        "        \"Gradient Boosting\": GradientBoostingRegressor(\n",
        "            n_estimators=200,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        ),\n",
        "        \"LightGBM-AFT\": LightGBMAFT(),\n",
        "        \"Neural Network\": CustomNNRegressor()\n",
        "    }\n",
        "\n",
        "    print(\"Evaluating models...\")\n",
        "    results_df = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
        "    print(\"\\nModel Evaluation:\\n\", results_df)\n",
        "\n",
        "    return models, results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"1000 Buses Trajectory Dataset (1).csv\"\n",
        "    models, results = main(file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
